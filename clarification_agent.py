# Fichier: clarification_agent.py

# La mission de cet agent a √©volu√© : il ne cr√©e plus un simple r√©sum√©, mais une description
# narrative d√©taill√©e du processus. Il a pour but d'identifier les actions,
# les acteurs, et surtout les potentielles conditions ("si ceci, alors cela...")
# pour pr√©parer le terrain √† l'agent de structuration.

import time
from typing import Dict
from dotenv import load_dotenv 
# retry : Biblioth√®que utilis√©e via un "d√©corateur" (@retry) pour relancer automatiquement
# une fonction si elle √©choue.
from retry import retry

# ValidationError : L'erreur sp√©cifique que Pydantic l√®ve quand les donn√©es ne
# correspondent pas au "plan" (sch√©ma).
from pydantic import ValidationError

# On importe les "plans" de donn√©es depuis notre fichier central state.py
from state import GraphState, ClarificationOutput
from llm import TogetherModelWrapper
load_dotenv()
# Initialisation du LLM
llm = TogetherModelWrapper(model_name="mistralai/Mixtral-8x7B-Instruct-v0.1")

# L'exception personnalis√©e reste ici car elle est sp√©cifique √† la logique de cet agent.
# C'est le "signal d'√©chec" que le d√©corateur @retry va √©couter.
class InvalidDescriptionError(Exception):
    """Lev√©e lorsque la description g√©n√©r√©e n'est pas valide."""
    pass

# Le d√©corateur @retry est plac√© juste au-dessus de la fonction qu'il doit surveiller.
# - InvalidDescriptionError : Il ne se d√©clenchera QUE si cette erreur sp√©cifique est lev√©e.
# - tries=3 : Il tentera au maximum 3 fois (1 essai initial + 2 re-essais).
# - delay=2 : Il attendra 2 secondes entre chaque tentative.
@retry(InvalidDescriptionError, tries=3, delay=2)
def generate_and_validate_description(question: str) -> str:
    """
    Appelle le LLM et valide la sortie en utilisant le sch√©ma Pydantic ClarificationOutput.
    Relance automatiquement en cas d'InvalidDescriptionError.
    """
    print("   - Tentative d'appel au LLM pour clarification...")
    
    # --- MODIFICATION CL√â : Le prompt est maintenant plus exigeant ---
    # Il demande une description narrative qui inclut les conditions et les r√©sultats.
    prompt = f"""
    [INST]Tu es un analyste m√©tier expert. Ta mission est de prendre la demande brute de l'utilisateur et de la transformer en une **description narrative d√©taill√©e** du processus.
    Cette description doit √™tre un paragraphe fluide qui explique les √©tapes principales, les points de d√©cision, et les diff√©rentes issues possibles.
    Ton texte servira de cahier des charges pour un autre agent IA qui devra le mod√©liser.

    **Exemple :**
    Demande utilisateur : "comment on fait les notes de frais ?"
    Description narrative attendue : "Le processus de gestion des notes de frais commence par la soumission des d√©penses par un employ√©. Ensuite, un manager doit examiner la demande. **Si la note est approuv√©e**, elle est transmise au service comptable pour remboursement. **Dans le cas contraire**, une notification de rejet est envoy√©e √† l'employ√©."

    Demande de l'utilisateur : "{question}"

    Description narrative d√©taill√©e du processus :[/INST]
    """
    
    # On appelle le LLM pour obtenir la description.
    raw_output = llm(prompt)
    description_str = str(raw_output)
    
    try:
        # On utilise le sch√©ma import√© (ClarificationOutput) pour valider la description.
        # Pydantic v√©rifie ici que la description n'est pas trop courte.
        validated_output = ClarificationOutput(description=description_str)
        
        # On appelle notre m√©thode de validation personnalis√©e pour v√©rifier le contenu.
        validated_output.validate_content()
        
        print("   - ‚úÖ Description valid√©e par Pydantic.")
        return validated_output.description
        
    except (ValidationError, ValueError) as e:
        # Si la validation par Pydantic ou notre m√©thode personnalis√©e √©choue...
        # ...on l√®ve notre erreur personnalis√©e pour que le d√©corateur @retry l'attrape.
        print(f"   - ‚ö†Ô∏è Validation √©chou√©e : {e}. D√©clenchement d'une nouvelle tentative.")
        raise InvalidDescriptionError(e)

def clarification_agent(state: GraphState) -> Dict:
    """
    Agent 1: Agent de Clarification.
    Orchestre l'appel √† la fonction de g√©n√©ration/validation et g√®re le r√©sultat final.
    """
    print("\n--- AGENT 1: Clarification et Description (avec @retry) ---")
    question = state["input_question"]
    
    try:
        # On appelle simplement notre fonction d√©cor√©e.
        # Toute la complexit√© de la boucle de retry est g√©r√©e par le d√©corateur.
        final_description = generate_and_validate_description(question)
        
        print("   - ‚úÖ Description finale obtenue avec succ√®s.")
        # On met √† jour l'√©tat avec la description et le signal pour passer √† l'agent suivant.
        return {
            "general_response": final_description,
            "next_action": "structure_sop" # "structure_sop" est le nom du prochain n≈ìud
        }
    except InvalidDescriptionError as e:
        # Si, apr√®s 3 tentatives, la fonction √©choue toujours, @retry
        # rel√®ve l'exception finale, que nous attrapons ici pour terminer proprement.
        print(f"   - ‚ùå √âchec final de la clarification apr√®s plusieurs tentatives. Erreur : {e}")
        return {
            "general_response": "Erreur : Impossible de g√©n√©rer une description claire.",
            "next_action": "end_with_error"
        }


# ==============================================================================
#  BLOC DE TEST UNITAIRE (INCHANG√â, TOUJOURS PERTINENT)
# ==============================================================================
if __name__ == '__main__':
    # Ce bloc permet de tester cet agent de mani√®re isol√©e.
    print("="*60)
    print("üöÄ TEST UNITAIRE: clarification_agent")
    print("="*60)
    
    # 1. On simule l'√©tat d'entr√©e que le graphe fournirait.
    test_state = {
        "input_question": "Comment faire pour g√©rer un retour produit d'un client ?",
        "conversation_history": [] # On inclut les cl√©s requises par GraphState, m√™me si elles sont vides.
    }
    
    # 2. On ex√©cute la fonction principale de l'agent.
    result_state = clarification_agent(test_state)
    
    # 3. On affiche le r√©sultat pour v√©rification.
    print("\n--- R√âSULTAT DU TEST ---")
    print(result_state)
    assert result_state.get("next_action") != "end_with_error", "Le test de base ne devrait pas √©chouer."
    print("\n‚úÖ Test de base r√©ussi.")
    
    